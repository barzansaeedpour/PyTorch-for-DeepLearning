{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOREU6Bal9hysH5JOg1oGjG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/barzansaeedpour/PyTorch-for-DeepLearning/blob/main/04_my_custom_dataset_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Importing PyTorch and setting up device-agnostic code"
      ],
      "metadata": {
        "id": "47ZYSNjmkfjw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9jxJ6MUbjh6j",
        "outputId": "ab248395-ac69-44b6-8026-368c3261428c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.4.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Note: this notebook requires torch >= 1.10.0\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device-agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dWma2sNXkh7n",
        "outputId": "8dd1a2ee-a2ce-4be1-ba87-d18a37a5958c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usGivKpAlPwo",
        "outputId": "63d63531-d839-4aee-cdc6-2ebdf0c704e7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Get data\n",
        "\n",
        "First thing's first we need some data.\n",
        "\n",
        "And like any good cooking show, some data has already been prepared for us.\n",
        "\n",
        "We're going to start small.\n",
        "\n",
        "Because we're not looking to train the biggest model or use the biggest dataset yet.\n",
        "\n",
        "Machine learning is an iterative process, start small, get something working and increase when necessary.\n",
        "\n",
        "The data we're going to be using is a subset of the [Food101 dataset](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/).\n",
        "\n",
        "Food101 is popular computer vision benchmark as it contains 1000 images of 101 different kinds of foods, totaling 101,000 images (75,750 train and 25,250 test).\n",
        "\n",
        "Can you think of 101 different foods?\n",
        "\n",
        "Can you think of a computer program to classify 101 foods?\n",
        "\n",
        "I can.\n",
        "\n",
        "A machine learning model!\n",
        "\n",
        "Specifically, a PyTorch computer vision model like we covered in [notebook 03](https://www.learnpytorch.io/03_pytorch_computer_vision/).\n",
        "\n",
        "Instead of 101 food classes though, we're going to start with 3: pizza, steak and sushi.\n",
        "\n",
        "And instead of 1,000 images per class, we're going to start with a random 10% (start small, increase when necessary).\n",
        "\n",
        "If you'd like to see where the data came from you see the following resources:\n",
        "* Original [Food101 dataset and paper website](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/).\n",
        "* [`torchvision.datasets.Food101`](https://pytorch.org/vision/main/generated/torchvision.datasets.Food101.html) - the version of the data I downloaded for this notebook.\n",
        "* [`extras/04_custom_data_creation.ipynb`](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/04_custom_data_creation.ipynb) - a notebook I used to format the Food101 dataset to use for this notebook.\n",
        "* [`data/pizza_steak_sushi.zip`](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/data/pizza_steak_sushi.zip) - the zip archive of pizza, steak and sushi images from Food101, created with the notebook linked above.\n",
        "\n",
        "Let's write some code to download the formatted data from GitHub.\n",
        "\n",
        "> **Note:** The dataset we're about to use has been pre-formatted for what we'd like to use it for. However, you'll often have to format your own datasets for whatever problem you're working on. This is a regular practice in the machine learning world."
      ],
      "metadata": {
        "id": "NoZWvVx5mUWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it...\n",
        "if image_path.is_dir():\n",
        "    print(f\"{image_path} directory exists.\")\n",
        "else:\n",
        "    print(f\"Did not find {image_path} directory, creating one...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Download pizza, steak, sushi data\n",
        "    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "        print(\"Downloading pizza, steak, sushi data...\")\n",
        "        f.write(request.content)\n",
        "\n",
        "    # Unzip pizza, steak, sushi data\n",
        "    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "        print(\"Unzipping pizza, steak, sushi data...\")\n",
        "        zip_ref.extractall(image_path)"
      ],
      "metadata": {
        "id": "7ZF43BRjla1N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce7fbc52-faa5-48d1-d03b-770884143b85"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did not find data/pizza_steak_sushi directory, creating one...\n",
            "Downloading pizza, steak, sushi data...\n",
            "Unzipping pizza, steak, sushi data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Become one with the data (data preparation)\n",
        "\n",
        "Dataset downloaded!\n",
        "\n",
        "Time to become one with it.\n",
        "\n",
        "\n",
        "*Data preparation is paramount. Before building a model, become one with the data.\n",
        "\n",
        "Before starting a project or building any kind of model, it's important to know what data you're working with.\n",
        "\n",
        "In our case, we have images of pizza, steak and sushi in standard image classification format.\n",
        "\n",
        "Image classification format contains separate classes of images in seperate directories titled with a particular class name.\n",
        "\n",
        "For example, all images of `pizza` are contained in the `pizza/` directory.\n",
        "\n",
        "This format is popular across many different image classification benchmarks, including [ImageNet](https://www.image-net.org/) (of the most popular computer vision benchmark datasets).\n",
        "\n",
        "You can see an example of the storage format below, the images numbers are arbitrary.\n",
        "\n",
        "```\n",
        "pizza_steak_sushi/ <- overall dataset folder\n",
        "    train/ <- training images\n",
        "        pizza/ <- class name as folder name\n",
        "            image01.jpeg\n",
        "            image02.jpeg\n",
        "            ...\n",
        "        steak/\n",
        "            image24.jpeg\n",
        "            image25.jpeg\n",
        "            ...\n",
        "        sushi/\n",
        "            image37.jpeg\n",
        "            ...\n",
        "    test/ <- testing images\n",
        "        pizza/\n",
        "            image101.jpeg\n",
        "            image102.jpeg\n",
        "            ...\n",
        "        steak/\n",
        "            image154.jpeg\n",
        "            image155.jpeg\n",
        "            ...\n",
        "        sushi/\n",
        "            image167.jpeg\n",
        "            ...\n",
        "```\n",
        "\n",
        "The goal will be to **take this data storage structure and turn it into a dataset usable with PyTorch**.\n",
        "\n",
        "> **Note:** The structure of the data you work with will vary depending on the problem you're working on. But the premise still remains: become one with the data, then find a way to best turn it into a dataset compatible with PyTorch.\n",
        "\n",
        "We can inspect what's in our data directory by writing a small helper function to walk through each of the subdirectories and count the files present.\n",
        "\n",
        "To do so, we'll use Python's in-built [`os.walk()`](https://docs.python.org/3/library/os.html#os.walk)."
      ],
      "metadata": {
        "id": "L70Ay2_UvF1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def walk_through_dir(dir_path):\n",
        "  \"\"\"\n",
        "  Walks through dir_path returning its contents.\n",
        "  Args:\n",
        "    dir_path (str or pathlib.Path): target directory\n",
        "\n",
        "  Returns:\n",
        "    A print out of:\n",
        "      number of subdiretories in dir_path\n",
        "      number of images (files) in each subdirectory\n",
        "      name of each subdirectory\n",
        "  \"\"\"\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "id": "YV55yVoDvvZi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walk_through_dir(image_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgCun_g4vwc0",
        "outputId": "884c05ac-3ec8-4ef9-927a-e1f321abc5cf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in 'data/pizza_steak_sushi'.\n",
            "There are 3 directories and 0 images in 'data/pizza_steak_sushi/train'.\n",
            "There are 0 directories and 75 images in 'data/pizza_steak_sushi/train/steak'.\n",
            "There are 0 directories and 78 images in 'data/pizza_steak_sushi/train/pizza'.\n",
            "There are 0 directories and 72 images in 'data/pizza_steak_sushi/train/sushi'.\n",
            "There are 3 directories and 0 images in 'data/pizza_steak_sushi/test'.\n",
            "There are 0 directories and 19 images in 'data/pizza_steak_sushi/test/steak'.\n",
            "There are 0 directories and 25 images in 'data/pizza_steak_sushi/test/pizza'.\n",
            "There are 0 directories and 31 images in 'data/pizza_steak_sushi/test/sushi'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excellent!\n",
        "\n",
        "It looks like we've got about 75 images per training class and 25 images per testing class.\n",
        "\n",
        "That should be enough to get started.\n",
        "\n",
        "Remember, these images are subsets of the original Food101 dataset.\n",
        "\n",
        "While we're at it, let's setup our training and testing paths."
      ],
      "metadata": {
        "id": "qPDziXi5v9l0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup train and testing paths\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\"\n",
        "\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtyHIFJOvy_5",
        "outputId": "334e5c56-04c8-4a81-8d0f-fc8a9ab001c9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PosixPath('data/pizza_steak_sushi/train'),\n",
              " PosixPath('data/pizza_steak_sushi/test'))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5TKpHBP9wKqb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}