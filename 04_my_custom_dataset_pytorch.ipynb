{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNsJ/oGIkMF1jaLbnQpa/W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/barzansaeedpour/PyTorch-for-DeepLearning/blob/main/04_my_custom_dataset_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Importing PyTorch and setting up device-agnostic code"
      ],
      "metadata": {
        "id": "47ZYSNjmkfjw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9jxJ6MUbjh6j",
        "outputId": "ab248395-ac69-44b6-8026-368c3261428c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.4.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Note: this notebook requires torch >= 1.10.0\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device-agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dWma2sNXkh7n",
        "outputId": "8dd1a2ee-a2ce-4be1-ba87-d18a37a5958c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usGivKpAlPwo",
        "outputId": "63d63531-d839-4aee-cdc6-2ebdf0c704e7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Get data\n",
        "\n",
        "First thing's first we need some data.\n",
        "\n",
        "And like any good cooking show, some data has already been prepared for us.\n",
        "\n",
        "We're going to start small.\n",
        "\n",
        "Because we're not looking to train the biggest model or use the biggest dataset yet.\n",
        "\n",
        "Machine learning is an iterative process, start small, get something working and increase when necessary.\n",
        "\n",
        "The data we're going to be using is a subset of the [Food101 dataset](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/).\n",
        "\n",
        "Food101 is popular computer vision benchmark as it contains 1000 images of 101 different kinds of foods, totaling 101,000 images (75,750 train and 25,250 test).\n",
        "\n",
        "Can you think of 101 different foods?\n",
        "\n",
        "Can you think of a computer program to classify 101 foods?\n",
        "\n",
        "I can.\n",
        "\n",
        "A machine learning model!\n",
        "\n",
        "Specifically, a PyTorch computer vision model like we covered in [notebook 03](https://www.learnpytorch.io/03_pytorch_computer_vision/).\n",
        "\n",
        "Instead of 101 food classes though, we're going to start with 3: pizza, steak and sushi.\n",
        "\n",
        "And instead of 1,000 images per class, we're going to start with a random 10% (start small, increase when necessary).\n",
        "\n",
        "If you'd like to see where the data came from you see the following resources:\n",
        "* Original [Food101 dataset and paper website](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/).\n",
        "* [`torchvision.datasets.Food101`](https://pytorch.org/vision/main/generated/torchvision.datasets.Food101.html) - the version of the data I downloaded for this notebook.\n",
        "* [`extras/04_custom_data_creation.ipynb`](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/04_custom_data_creation.ipynb) - a notebook I used to format the Food101 dataset to use for this notebook.\n",
        "* [`data/pizza_steak_sushi.zip`](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/data/pizza_steak_sushi.zip) - the zip archive of pizza, steak and sushi images from Food101, created with the notebook linked above.\n",
        "\n",
        "Let's write some code to download the formatted data from GitHub.\n",
        "\n",
        "> **Note:** The dataset we're about to use has been pre-formatted for what we'd like to use it for. However, you'll often have to format your own datasets for whatever problem you're working on. This is a regular practice in the machine learning world."
      ],
      "metadata": {
        "id": "NoZWvVx5mUWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it...\n",
        "if image_path.is_dir():\n",
        "    print(f\"{image_path} directory exists.\")\n",
        "else:\n",
        "    print(f\"Did not find {image_path} directory, creating one...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Download pizza, steak, sushi data\n",
        "    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "        print(\"Downloading pizza, steak, sushi data...\")\n",
        "        f.write(request.content)\n",
        "\n",
        "    # Unzip pizza, steak, sushi data\n",
        "    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "        print(\"Unzipping pizza, steak, sushi data...\")\n",
        "        zip_ref.extractall(image_path)"
      ],
      "metadata": {
        "id": "7ZF43BRjla1N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce7fbc52-faa5-48d1-d03b-770884143b85"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did not find data/pizza_steak_sushi directory, creating one...\n",
            "Downloading pizza, steak, sushi data...\n",
            "Unzipping pizza, steak, sushi data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "b6kMamVDsG4k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}